---
title: "SVR VOC index sensor 1 - 10th"
author: "Marina Paldauf"
date: "05/05/2021"
output:
  html_document:
    toc: yes
    toc_depth: 2
    float_toc: yes
    urlcolour: blue
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("RMySQL")
library("reshape2")
library("GGally")
library("dplyr")
library("ggplot2")
library("ggcorrplot")
library("caret")
library("cowplot")
library("corrplot")
library("devtools")
library("ggbiplot")
library("purrr")
library("viridis")
library("lubridate")
library("gridExtra")
library("FactoMineR")
library("factoextra")
library("normalr")
library("rgl")
library("rstatix")
library("readr")
library("lares")
library("pROC")
library("quantmod")
library("e1071")
```

# Getting Data Markova

Importing data set.

```{r data, warning=FALSE}

d.mrakova.main <- read.csv("sensor_data_2020.csv")

d.mrakova.main.predict <- d.mrakova.main %>% 
  mutate(date = as.POSIXct(created_at, "%Y-%m-%d %H:%M:%S")) %>%
  filter(date <= as.POSIXct("2020-12-31 23:59:59") & date >= as.POSIXct("2020-08-15 00:00:00"))

```


# Cleaning data

Keeping only needed variables and creating a variable to handle time variable and removing two extreme pressure outliers due to sensor faultiness.

```{r cleaning, echo=FALSE, warning=FALSE}

d.mrakova.main.predict <- d.mrakova.main.predict %>% select(X, date, source, meta_sn, T, RH, CO2, p, ambient_light, VOC_index, PM10, created_at) %>%
  mutate(year = year(as.Date(created_at))) %>%
  mutate(month = month(as.Date(created_at))) %>%
  mutate(day = day(as.Date(created_at))) %>%
  mutate(hour = as.numeric(strftime(created_at, "%H"))) %>%
  mutate(week = week(as.Date(created_at)))


# remove outliers - two main ones for pressure variable
d.mrakova.predict <- d.mrakova.main.predict
d.mrakova.predict <- d.mrakova.predict %>% 
  arrange(desc(p))
d.mrakova.predict <- d.mrakova.predict[-c(1,2), ]

```

Removing duplicates.

```{r descriptive3, echo=FALSE, warning=FALSE}

d.mrakova.dup.predict <- d.mrakova.predict

# remove duplicates for further analysis
d.mrakova.non.dup.predict <- d.mrakova.dup.predict %>% distinct(created_at, .keep_all = TRUE)

```


Removing outliers. Shown bellow, number of observations with outliers (1st value) and without (2nd value).

```{r outliers, echo=FALSE, warning=FALSE}

X <- split(d.mrakova.non.dup.predict, d.mrakova.non.dup.predict$meta_sn)
d.mrakova.sensor1 <- X[[1]]
#d.mrakova.sensor2 <- X[[2]]


#prediction dataset

#complete dataset
outliers.no_total <- d.mrakova.sensor1
outliers.no <- d.mrakova.sensor1

# removing outliers

nrow(outliers.no)

#VOC index
Q1 <- quantile(outliers.no_total$VOC_index, probs=c(.25, .75), na.rm = FALSE)

iqr1 <- IQR(outliers.no_total$VOC_index)

up1 <- Q1[2]+1.5*iqr1 # Upper Range  
low1<- Q1[1]-1.5*iqr1 # Lower Range

outliers.no <- outliers.no %>% filter(VOC_index >= low1 & VOC_index <= up1)

#CO2
Q2 <- quantile(outliers.no_total$CO2, probs=c(.25, .75), na.rm = FALSE)

iqr2<- IQR(outliers.no_total$CO2)

up2 <- Q2[2]+1.5*iqr2 # Upper Range  
low2<- Q2[1]-1.5*iqr2 # Lower Range

outliers.no <- outliers.no %>% filter(CO2 >= low2 & CO2 <= up2)

#p
Q3 <- quantile(outliers.no_total$p, probs=c(.25, .75), na.rm = FALSE)
iqr3 <- IQR(outliers.no_total$p)

up3 <- Q3[2]+1.5*iqr3 # Upper Range  
low3<- Q3[1]-1.5*iqr3 # Lower Range

outliers.no <- outliers.no %>% filter(p >= low3 & p <= up3)


#RH
Q4 <- quantile(outliers.no_total$RH, probs=c(.25, .75), na.rm = FALSE)

iqr4 <- IQR(outliers.no_total$RH)

up4 <- Q4[2]+1.5*iqr4 # Upper Range  
low4 <- Q4[1]-1.5*iqr4 # Lower Range

outliers.no <- outliers.no %>% filter(RH >= low4 & RH <= up4)


#PM10
Q5 <- quantile(outliers.no_total$PM10, probs=c(.25, .75), na.rm = FALSE)

iqr5 <- IQR(outliers.no_total$PM10)

up5 <- Q5[2]+1.5*iqr5 # Upper Range  
low5 <- Q5[1]-1.5*iqr5 # Lower Range

outliers.no <- outliers.no %>% filter(PM10 >= low5 & PM10 <= up5)


#ambient_light
Q6 <- quantile(outliers.no_total$ambient_light, probs=c(.25, .75), na.rm = FALSE)

iqr6 <- IQR(outliers.no_total$ambient_light)

up6 <- Q6[2]+1.5*iqr6 # Upper Range  
low6<- Q6[1]-1.5*iqr6 # Lower Range

outliers.no <- outliers.no %>% filter(ambient_light >= low6 & ambient_light <= up6)
nrow(outliers.no)

d.mrakova.non.dup.predict <- outliers.no

summary(d.mrakova.non.dup.predict)
```


## Logarithmic manipulation

Data set's main descriptive statistics after logarithmic transformation.

```{r logpredict}

CO2 <- log(d.mrakova.non.dup.predict$CO2)
p <- log(d.mrakova.non.dup.predict$p)
ambient_light <- log(d.mrakova.non.dup.predict$ambient_light)
T <- log(d.mrakova.non.dup.predict$T)
RH <- log(d.mrakova.non.dup.predict$RH)
VOC_index <- log(d.mrakova.non.dup.predict$VOC_index)
PM10 <- log(d.mrakova.non.dup.predict$PM10)

d.mrakova.svm.log <- d.mrakova.non.dup.predict %>% select(meta_sn, created_at)
d.mrakova.svm.log<- cbind(d.mrakova.svm.log, CO2, p, ambient_light, VOC_index, PM10, RH, T)

d.mrakova.svm.log$CO2[which(!is.finite(d.mrakova.svm.log$CO2))] <- 0
d.mrakova.svm.log$VOC_index[which(!is.finite(d.mrakova.svm.log$VOC_index))] <- 0
d.mrakova.svm.log$p[which(!is.finite(d.mrakova.svm.log$p))] <- 0
d.mrakova.svm.log$ambient_light[which(!is.finite(d.mrakova.svm.log$ambient_light))] <- 0
d.mrakova.svm.log$PM10[which(!is.finite(d.mrakova.svm.log$PM10))] <- 0

summary(d.mrakova.svm.log)

```

# Support vector model for sensor 1, VOC index

Splitting data into sensors, reducing dataset to keep every 10th observation, standardization and splitting into training and testing data set.
The amount of observations after reduction and the summary of training data set.

```{r predsens1 VOC}

#X <- split(d.mrakova.svm.log, d.mrakova.svm.log$meta_sn)

d.mrakova.sensor1 <- d.mrakova.svm.log
#d.mrakova.sensor2 <- X[[2]]


#reducing dataset 
d.mrakova.sensor1.small = d.mrakova.sensor1[seq(1, nrow(d.mrakova.sensor1), 10), ]
nrow(d.mrakova.sensor1.small)

d.mrakova.sensor1.selectedVOC<- d.mrakova.sensor1.small %>% select(T, RH, PM10, p, ambient_light, CO2, VOC_index, created_at)

#standardizacija
VOC_1_standardized <- 
  d.mrakova.sensor1.selectedVOC %>% 
  mutate(PM10 = scale(PM10)) %>% 
  mutate(CO2 = scale(CO2)) %>%
  mutate(VOC_index = scale(VOC_index)) %>%
  mutate(T = scale(T))%>%
  mutate(RH = scale(RH)) %>%
  mutate(p = scale(p)) %>%
  mutate(ambient_light = scale(ambient_light))

# VOC
validation_index <- createDataPartition(VOC_1_standardized$VOC_index, p=0.60, list=FALSE)
validation <- VOC_1_standardized[-validation_index,]
d.mrakova.sensor1.selectedVOC <- VOC_1_standardized[validation_index,]

summary(d.mrakova.sensor1.selectedVOC)

```

## Support vector regression model

### Fit SVR model and visualize using scatter plot

Training and prediction.

```{r SVRbasic}

# regression training model SVM
model <- svm(VOC_index~T + RH + PM10 + p + ambient_light + CO2, data = d.mrakova.sensor1.selectedVOC)
summary(model)

#Predict using SVM regression
pred_VOC_s1 = predict(model, newdata=validation)

validation_new1_s1 <- cbind(validation, pred_VOC_s1)

```


Overlay SVM Predictions on Scatter Plot

```{r plotpredact, WARNING=FALSE}
#Overlay SVM Predictions on Scatter Plot

validation_new1_s1_graph <- validation_new1_s1 %>%
   mutate(date = as.POSIXct(created_at), format="%Y-%m-%d %H:%M:%S") %>% select(date, pred_VOC_s1, VOC_index) %>%
  gather(key = "variable", value = "value", -date)

ggplot(validation_new1_s1_graph, aes(x = date, y = value)) + 
  geom_line(aes(color = variable, linetype = variable)) + 
  scale_color_manual(values = c("darkred", "steelblue"))

```

RMSE

```{r RMSE}

# RMSE
sqrt(mean((validation_new1_s1$VOC_index - validation_new1_s1$pred_VOC_s1)^2))

```

R^2

```{r r21}

# R2
cor(validation_new1_s1$VOC_index, validation_new1_s1$pred_VOC_s1) ^ 2

```


